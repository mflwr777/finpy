{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "personal-retention",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'C:\\\\code\\\\python_for_the_financial_economist\\\\')\n",
    "\n",
    "\"\"\"\n",
    "Magic commands\n",
    "\"\"\"\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# animations, etc. requires below magic command\n",
    "# %matplotlib notebook\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Load relevant packages\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Polygon\n",
    "from matplotlib import animation, cm\n",
    "\n",
    "from scipy import stats\n",
    "from scipy import optimize\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "#import autograd\n",
    "# functions to approx derivative and hessian \n",
    "from statsmodels.tools.numdiff import approx_fprime, approx_hess\n",
    "\n",
    "\"\"\"\n",
    "Own packages\n",
    "\"\"\"\n",
    "\n",
    "from codelib.visualization.layout import DefaultStyle\n",
    "DefaultStyle();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "funded-accident",
   "metadata": {},
   "source": [
    "# Introduction to estimation \n",
    "\n",
    "Estimation is key in financial economics!  The distribution of market invariants (e.g. returns) will generally be unknown and even if we can assume a particular distribution we need to be able to estimate the parameters describing the particular distribution. \n",
    "\n",
    "The choice of estimator will depend on a range of factors. Generally, the [variance-bias tradeoff](https://en.wikipedia.org/wiki/Bias%E2%80%93variance_tradeoff) tells us that we with large amounts of data can apply very flexible non-parametric estimators while we may need to impose distributional assumptions or even shrinkage with less data. \n",
    "\n",
    "## What is an estimator? \n",
    "\n",
    "An [estimator](https://en.wikipedia.org/wiki/Estimator), typically denoted $\\hat{\\theta} (\\mathbf{X})$, maps a random sample $X_1, ..., X_n$ (stacked in the vector $\\mathbf{X}$) defined by e.g. the pdf $f_X(x;\\theta)$, where $\\theta$ is an unknown parameter, to a set of _sample estimates_. It is important to note that the estimator is a function of random variables and therefore itself a random variable. \n",
    "\n",
    "For a particular realization of the random sample $x_1, ..., x_n$ (stacked in the vector $\\mathbf{x}$), we obtain the estimate $\\hat{\\theta} (\\mathbf{x})$ which is a fixed value. \n",
    "\n",
    "Some well-known estimators include the _sample mean_\n",
    "\n",
    "$$\n",
    "\\begin{equation*}\n",
    "\\bar{X} = \\frac{1}{n} \\sum_{i=1}^n X_i\n",
    "\\end{equation*}\n",
    "$$\n",
    "\n",
    "The _sample variance_\n",
    "$$\n",
    "\\begin{equation*}\n",
    "S^2 = \\frac{1}{n-1} \\sum_{i=1}^n (X_i - \\bar{X})^2\n",
    "\\end{equation*}\n",
    "$$\n",
    "\n",
    "The _sample covariance_\n",
    "\n",
    "$$\n",
    "\\begin{equation*}\n",
    "C_{X,Y} = \\frac{1}{n} \\sum_{i=1}^n (X_i - \\bar{X})(Y_i - \\bar{Y})\n",
    "\\end{equation*}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Properties of estimators \n",
    "\n",
    "We will discuss some important properties of estimators\n",
    "\n",
    "* Unbiasedness\n",
    "* Consistency\n",
    "* Efficiency\n",
    "* Asymptotic normality\n",
    "\n",
    "### Unbiasedness\n",
    "\n",
    "Estimators will take on different values from sample to sample (the estimate), but we would like the property that we on average get the right estimate. \n",
    "\n",
    "An estimator is said to be [unbiased](https://en.wikipedia.org/wiki/Bias_of_an_estimator) if its expected value is equal to the true value $\\theta$: \n",
    "\n",
    "$$\n",
    "\\text{E}[\\hat{\\theta} (\\mathbf{X})]  = \\theta\n",
    "$$\n",
    "\n",
    "__Example: Sample mean__\n",
    "\n",
    "Let $X_1,...,X_n$ be an independent sample of size $n$ all with the same pdf and mean $\\text{E}[X_i] = \\mu$. Define the sample mean\n",
    "\n",
    "$$\n",
    "\\begin{equation*}\n",
    "\\bar{X}_n = \\frac{1}{n} \\sum_{i=1}^n X_i\n",
    "\\end{equation*} \n",
    "$$\n",
    "\n",
    "Then due to independence, \n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "E[\\bar{X}_n] &=  \\frac{1}{n} \\sum_{i=1}^n \\text{E}[X_i] = \\mu  \\\\\n",
    "\\text{Var}[\\bar{X}_n] &= \\frac{1}{n^2} \\sum_{i=1}^n \\text{Var}[X_i] = \\frac{\\sigma^2}{n}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Thus, the sample mean is an unbiased estimator. \n",
    "\n",
    "__Example: A single realization__\n",
    "\n",
    "Choosing the value of a single realization will also be an unbiased estimator since $\\text{E}[X_i] = \\mu$. The problem is of course that the variance of this estimator is $\\text{Var}[X_i] = \\sigma^2 > \\frac{\\sigma^2}{n}$. \n",
    "\n",
    "__Example: Sample variance__\n",
    "\n",
    "An natural estimator for the variance is given by\n",
    "\n",
    "$$\n",
    "\\begin{equation*}\n",
    "\\hat{\\sigma}^2 = \\frac{1}{n} \\sum_{i=1}^n (X_i - \\bar{X})^2\n",
    "\\end{equation*}\n",
    "$$\n",
    "\n",
    "However, one can show that \n",
    "$$\n",
    "\\begin{equation*}\n",
    "\\text{E}[\\hat{\\sigma}^2] = \\frac{n-1}{n} \\sigma^2\n",
    "\\end{equation*}\n",
    "$$\n",
    "\n",
    "Hence, it is not an unbiased estimator and we therefore typically use \n",
    "\n",
    "$$\n",
    "\\begin{equation*}\n",
    "S^2 = \\frac{1}{n-1} \\sum_{i=1}^n (X_i - \\bar{X})^2\n",
    "\\end{equation*}\n",
    "$$\n",
    "\n",
    "\n",
    "### Consistency\n",
    "\n",
    "An estimator $\\hat{\\theta}(\\mathbf{X})$ is said to be [consistent](https://en.wikipedia.org/wiki/Consistent_estimator) for $\\theta$ if it converges in probability to $\\theta$ - that is, if for all $\\varepsilon>0$, \n",
    "\n",
    "$$\n",
    "\\begin{equation*}\n",
    "\\lim_{n\\to\\infty} P(\\vert \\hat{\\theta}(\\mathbf{X}) - \\theta\\vert < \\varepsilon) = 1\n",
    "\\end{equation*}\n",
    "$$\n",
    "\n",
    "which we also will write as \n",
    "\n",
    "$$\n",
    "\\text{plim } \\hat{\\theta}(\\mathbf{X}) = \\theta\n",
    "$$\n",
    "\n",
    "For consistency, it is sufficient to show that (almost sure convergence)\n",
    "\n",
    "$$\n",
    "\\begin{equation*}\n",
    "\\lim_{n\\to \\infty} \\text{E}[\\hat{\\theta}(\\mathbf{X})] = \\theta\n",
    "\\end{equation*}\n",
    "$$\n",
    "\n",
    "and\n",
    "\n",
    "$$\n",
    "\\begin{equation*}\n",
    "\\lim_{n\\to \\infty}\\text{Var}[\\hat{\\theta}(\\mathbf{X})] = 0\n",
    "\\end{equation*}\n",
    "$$\n",
    "\n",
    "__Example: The sample mean__\n",
    "\n",
    "Again, let $X_1,...,X_n$ be an independent sample of size $n$ all with the same pdf and mean $\\text{E}[X_i] = \\mu$. \n",
    "\n",
    "The [Law of Large Numbers (LLN)](https://en.wikipedia.org/wiki/Law_of_large_numbers)  tells us (under some regularity conditions) that \n",
    "\n",
    "$$\n",
    "\\begin{equation*}\n",
    "\\text{plim } \\bar{X}_n = \\mu\n",
    "\\end{equation*}\n",
    "$$\n",
    "or more precisely \n",
    "\n",
    "$$\n",
    "\\begin{equation*}\n",
    "\\lim_{n \\to \\infty} P(\\vert \\bar{X}_n - \\mu \\vert > \\varepsilon) = 0\n",
    "\\end{equation*}\n",
    "$$\n",
    "\n",
    "for all $\\varepsilon>0$. We call this for convergence in probability. \n",
    "\n",
    "We note that \n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\text{E}[\\bar{X}_n] &=  \\frac{1}{n} \\sum_{i=1}^n \\text{E}[X_i] = \\mu  \\\\\n",
    "\\text{Var}[\\bar{X}_n] &= \\frac{1}{n^2} \\sum_{i=1}^n \\text{Var}[X_i] = \\frac{\\sigma^2}{n}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "implying that the sample mean is unbiased and the variance converges to zero with the sample size. Thus, we have almost sure convergence. \n",
    "\n",
    "As an example, we consider the uniform distribution $X \\sim U(-5,5)$. Draw 10, 100, 500 and 1000 observations from the uniform distribution 10,000 times, calculate the sample mean for each iteration and blot the histogram of the sample means.\n",
    "\n",
    "We see that the distribution collapses around the true value!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "round-atlantic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Draw uniform numbers\n",
    "\"\"\"\n",
    "a = -5.0\n",
    "b = 5.0\n",
    "\n",
    "uniform_data = np.random.uniform(low=a, high=b, size=(1000, 10000))\n",
    "\n",
    "true_var = (b-a)**2/12\n",
    "true_mean = (a + b)/2\n",
    "\n",
    "fig, ax_ = plt.subplots(2,2, figsize=(12,8))\n",
    "\n",
    "ax_ = ax_.flatten()\n",
    "\n",
    "\n",
    "for i, N in enumerate([10, 100, 500, 1000]): \n",
    "\n",
    "    ax = ax_[i]\n",
    "    \n",
    "    # get section of generated data\n",
    "    data = uniform_data[:N, :]\n",
    "    \n",
    "    # calculate sample means\n",
    "    sample_means = np.mean(data, axis=0)\n",
    "    \n",
    "    # plot histogram \n",
    "    ax.hist(sample_means, color=\"gray\", bins=100, zorder=1, density=True)\n",
    "    \n",
    "    ax.set_title(\"Histogram of sample mean for N = \" + str(N))\n",
    "    ax.set_axisbelow(True)\n",
    "    ax.set_xlim([-3.5,3.5]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "signal-future",
   "metadata": {},
   "source": [
    "### Efficiency \n",
    "\n",
    "If we have two unbiased estimators for a parameter $\\theta$, $\\hat{\\theta}_1$ and $\\hat{\\theta}_2$, then if \n",
    "\n",
    "$$\n",
    "\\begin{equation*}\n",
    "\\text{Var}[\\hat{\\theta}_1] < \\text{Var}[\\hat{\\theta}_2]\n",
    "\\end{equation*}\n",
    "$$\n",
    "we say that $\\hat{\\theta}_1$ is more efficient than $\\hat{\\theta}_2$.\n",
    "\n",
    "\n",
    "A classical example (already mentioned) is that an element in a sample $X_i$ is an unbiased estimator of the expected value, just as the sample mean\n",
    "\n",
    "$$\n",
    "\\begin{equation*}\n",
    "\\text{E}[X_i] = \\mu\n",
    "\\end{equation*}\n",
    "$$\n",
    "\n",
    "However, this estimator has the variance $\\sigma^2$ while the variance of the sample mean is \n",
    "\n",
    "$$\n",
    "\\begin{equation*}\n",
    "\\text{Var}[\\bar{X}] = \\frac{1}{n^2}\\sum_{i=1}^n \\text{Var}[X_i] = \\frac{\\sigma^2}{n}\n",
    "\\end{equation*}\n",
    "$$\n",
    "\n",
    "Clearly more efficient!\n",
    "\n",
    "__Cramér-Rao's lower bound__\n",
    "\n",
    "It will generally hold that if we have a random sample $X_1,...,X_n$ from the pdf $f_X(x;\\theta)$, where $\\theta$ is an unknown parameter and the estimator $\\hat{\\theta}(\\mathbf{X})$, then \n",
    "\n",
    "$$\n",
    "\\begin{equation*}\n",
    "\\text{Var}[\\hat{\\theta}] \\geq \\left[n \\text{E} \\left[ \\left(\\frac{\\partial \\ln f_X(X; \\theta)}{\\partial \\theta} \\right)^2\\right] \\right]^{-1} = \\left[ -n \\text{E} \\left[ \\frac{\\partial^2 \\ln f_X(X; \\theta)}{\\partial \\theta^2}\\right]\\right]^{-1}\n",
    "\\end{equation*}\n",
    "$$\n",
    "\n",
    "which is known as [Cramér-Rao's lower bound](https://en.wikipedia.org/wiki/Cram%C3%A9r%E2%80%93Rao_bound). We will later see that the maximum-likelihood estimator satisfies Cramér-Rao's lower bound ensuring that the maximum-likelihood estimator is the most efficient. \n",
    "\n",
    "__Example: Sample mean__\n",
    "\n",
    "Let $X_1,...,X_n$ be an independent sample of size $n$ all with $X_i \\sim N(\\mu, \\sigma^2)$. Then, we have\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\ln f_X(X; \\mu, \\sigma)}{\\partial \\mu} = \\frac{\\partial }{\\partial \\mu} \\left[- \\ln (\\sigma \\sqrt{2\\pi}) -\\frac{(X-\\mu)^2}{2 \\sigma^2} \\right] = -2 \\frac{X-\\mu}{2 \\sigma^2} = -\\frac{X-\\mu}{ \\sigma^2} \n",
    "$$\n",
    "\n",
    "and \n",
    "\n",
    "$$\n",
    "\\text{E}\\left[ \\left(-\\frac{X-\\mu}{ \\sigma^2} \\right)^2 \\right] = \\text{E}\\left[ \\frac{1}{\\sigma^2} \\frac{(X-\\mu)^2}{ \\sigma^2} \\right] =  \\frac{1}{\\sigma^2}  \\frac{ \\text{E}\\left[(X-\\mu)^2 \\right]}{ \\sigma^2} = \\frac{1}{\\sigma^2}  \\frac{ \\sigma^2}{ \\sigma^2} = \\frac{1}{\\sigma^2} \n",
    "$$\n",
    "\n",
    "Thus, the lower-bound for the variance is \n",
    "\n",
    "$$\n",
    "\\text{Var}[\\hat{\\mu}] \\geq \\left[n  \\frac{1}{\\sigma^2} \\right]^{-1} = \\frac{\\sigma^2}{n}\n",
    "$$\n",
    "\n",
    "showing that the sample mean is the most efficient estimator (unbiased) in the normal case. \n",
    "\n",
    "\n",
    "### Asymptotic normality \n",
    "\n",
    "A consistent estimator is said to be asymptotically normally distributed if the distribution of the estimator converges to a normal distribution, typically, at the rate $1 / \\sqrt{n}$ (the standard deviation shrinks at this rate). We will write \n",
    "\n",
    "$$\n",
    "\\sqrt{n} (\\hat{\\theta} - \\theta) \\to^d N(0, V)\n",
    "$$\n",
    "\n",
    "where $V/n$ is called the asymptotic variance. \n",
    "\n",
    "__Example: Sample mean__\n",
    "\n",
    "[The Central Limit Theorem (CLT)](https://en.wikipedia.org/wiki/Central_limit_theorem) tells us that for an iid random sample of size $n$ and if $\\sigma < \\infty$\n",
    "\n",
    "$$\n",
    "\\begin{equation*}\n",
    "\\lim_{n\\to \\infty} P\\left(\\frac{\\bar{X}_n - \\mu}{\\sigma/\\sqrt{n}} < z \\right) = \\Phi(z)\n",
    "\\end{equation*}\n",
    "$$\n",
    "where $\\Phi(z)$ denotes the standard normal cdf. \n",
    "\n",
    "It follows directly that \n",
    "\n",
    "$$\n",
    "\\sqrt{n}(\\bar{X}_n - \\mu) \\to^d N\\left(0, \\frac{\\sigma^2}{n}\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "isolated-yeast",
   "metadata": {},
   "source": [
    "## A brief look at Ordinary Least Squares (OLS)\n",
    "\n",
    "We will write a linear regression model (using matrix notation) as \n",
    "\n",
    "$$\n",
    "\\mathbf{y} = \\mathbf{X}\\boldsymbol{\\beta} + \\mathbf{e}\n",
    "$$\n",
    "\n",
    "where $\\mathbf{y}$ is the $n \\times 1$ vector of dependent variables, $\\mathbf{X}$ is the $n \\times k$ matrix of regressors (independent variables) and $\\mathbf{e}$ is the $n \\times 1$ error vector. \n",
    "\n",
    "As the name implies, the OLS estimator minimizes the sum of squared residuals \n",
    "\n",
    "$$\n",
    "Q_n (\\boldsymbol{\\beta}) = \\sum_{i=1}^n (y_i - \\mathbf{x}_i^\\top \\boldsymbol{\\beta} )^2 = (\\mathbf{y} - \\mathbf{X}\\boldsymbol{\\beta})^\\top (\\mathbf{y} - \\mathbf{X}\\boldsymbol{\\beta}) = \\mathbf{e}^\\top \\mathbf{e}\n",
    "$$\n",
    "\n",
    "Taking the derivative wrt. $\\boldsymbol{\\beta}$ and setting equal to zero yields the estimator \n",
    "\n",
    "$$\n",
    "\\hat{\\boldsymbol{\\beta}}_{OLS} = (\\mathbf{X}^\\top \\mathbf{X})^{-1} \\mathbf{X}^\\top \\mathbf{y}\n",
    "$$\n",
    "\n",
    "\n",
    "### Properties of OLS\n",
    "\n",
    "__Note__: It is not expected that you know all the finer details in deriving the asymptotic properties of e.g. the OLS estimator, but only how to implement derived formulas in Python. \n",
    "\n",
    "__Consistency__\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\hat{\\boldsymbol{\\beta}}_{OLS} &= (\\mathbf{X}^\\top \\mathbf{X})^{-1} \\mathbf{X}^\\top \\mathbf{y} \\\\\n",
    "&= (\\mathbf{X}^\\top \\mathbf{X})^{-1} \\mathbf{X}^\\top (\\mathbf{X}\\boldsymbol{\\beta} + \\mathbf{e}) \\\\\n",
    "&= (\\mathbf{X}^\\top \\mathbf{X})^{-1} \\mathbf{X}^\\top \\mathbf{X}\\boldsymbol{\\beta} + (\\mathbf{X}^\\top \\mathbf{X})^{-1} \\mathbf{X}^\\top \\mathbf{e} \\\\\n",
    "&= \\boldsymbol{\\beta} + (\\mathbf{X}^\\top \\mathbf{X})^{-1} \\mathbf{X}^\\top \\mathbf{e} \\\\\n",
    "&= \\boldsymbol{\\beta} + \\left(\\frac{1}{n}\\mathbf{X}^\\top \\mathbf{X}\\right)^{-1} \\frac{1}{n}\\mathbf{X}^\\top \\mathbf{e} \n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Basically, for consistency we need (without going into details)\n",
    "\n",
    "$$\n",
    "\\text{plim} \\frac{1}{n}\\mathbf{X}^\\top \\mathbf{X} = \\lim \\frac{1}{n} \\text{E} \\left[ \\mathbf{X}^\\top\\mathbf{X} \\right]  =  \\mathbf{M_{xx}}\n",
    "$$\n",
    "\n",
    "where $\\mathbf{M_{xx}}$ is a non-singular matrix (invertible), and \n",
    "\n",
    "$$\n",
    "\\text{plim} \\frac{1}{n}\\mathbf{X}^\\top \\mathbf{e} =  \\lim \\frac{1}{n} \\text{E} \\left[ \\mathbf{X}^\\top\\mathbf{e} \\right] =\\mathbf{0}\n",
    "$$\n",
    "\n",
    "requiring the regressors and error term to be uncorrelated. \n",
    "\n",
    "__Asymptotic normality__\n",
    "\n",
    "Rewritting the above expression yields \n",
    "\n",
    "$$\n",
    "\\sqrt{n}(\\hat{\\boldsymbol{\\beta}}_{OLS} - \\boldsymbol{\\beta}) = \\left(\\frac{1}{n}\\mathbf{X}^\\top \\mathbf{X}\\right)^{-1} \\frac{1}{\\sqrt{n}}\\mathbf{X}^\\top \\mathbf{e} \n",
    "$$\n",
    "\n",
    "If we can apply a CLT to $\\frac{1}{\\sqrt{n}}\\mathbf{X}^\\top \\mathbf{e}$ such that it converges to multivariate normal distribution with finite, non-singular covariance matrix, we will have asymptotic normality. \n",
    "\n",
    "Assuming that \n",
    "\n",
    "$$\n",
    "\\frac{1}{\\sqrt{n}}\\mathbf{X}^\\top \\mathbf{e} \\to^d N(\\mathbf{0}, \\mathbf{M_{x\\Omega x}})\n",
    "$$\n",
    "\n",
    "with  (here $\\boldsymbol{\\Omega}=\\text{E}[\\mathbf{e} \\mathbf{e}^\\top \\vert \\mathbf{X}] = \\text{Diag}[\\sigma_i^2]$ is the covariance matrix of the errors)\n",
    "\n",
    "$$\n",
    "\\text{plim} \\frac{1}{n}\\mathbf{X}^\\top \\mathbf{e} \\mathbf{e}^\\top\\mathbf{X} = \\text{plim} \\frac{1}{n}\\mathbf{X}^\\top  \\boldsymbol{\\Omega} \\mathbf{X}  = \\mathbf{M_{x\\Omega x}}\n",
    "$$\n",
    "\n",
    "then it will be possible to show that \n",
    "\n",
    "$$\n",
    "\\sqrt{n}(\\hat{\\boldsymbol{\\beta}}_{OLS} - \\boldsymbol{\\beta}) \\to^d N\\left(\\mathbf{0}, \\mathbf{M_{xx}}^{-1} \\mathbf{M_{x\\Omega x}}\\mathbf{M_{xx}}^{-1}\\right)\n",
    "$$\n",
    "\n",
    "__Homoskedasticity vs. heteroskedasticity__\n",
    "\n",
    "If $\\boldsymbol{\\Omega}=\\text{E}[\\mathbf{e}^\\top \\mathbf{e} \\vert \\mathbf{X}] = \\text{Diag}[\\sigma^2] = \\sigma^2 \\mathbf{I}$ then the error term is said to be homoskedastic and \n",
    "\n",
    "$$\n",
    "\\sqrt{n}(\\hat{\\boldsymbol{\\beta}}_{OLS} - \\boldsymbol{\\beta}) \\to^d N\\left(\\mathbf{0}, \\sigma^2 \\mathbf{M_{xx}}^{-1} \\mathbf{M_{xx}}\\mathbf{M_{xx}}^{-1}\\right) = N\\left(\\mathbf{0}, \\sigma^2 \\mathbf{M_{xx}}^{-1} \\right) \n",
    "$$\n",
    "\n",
    "where we will estimate $\\hat{\\mathbf{M}}_{\\mathbf{xx}} = \\frac{1}{n} \\mathbf{X}^\\top\\mathbf{X}$ and $\\sigma^2$ using the sample variance. \n",
    "\n",
    "$$\n",
    "S^2 = \\frac{1}{n - k} \\hat{\\mathbf{e}}^\\top \\hat{\\mathbf{e}}\n",
    "$$\n",
    "\n",
    "This leads to the variance estimator of the OLS estimator\n",
    "\n",
    "$$\n",
    "\\hat{\\text{Var}}[\\hat{\\boldsymbol{\\beta}}_{OLS}] = S^2 \\left( \\mathbf{X}^\\top\\mathbf{X} \\right)^{-1}\n",
    "$$\n",
    "\n",
    "If the error term is heteroskedastic then $\\sigma_i^2$ differs between observations. [Heteroscedastic robust standard errors](https://en.wikipedia.org/wiki/Heteroscedasticity-consistent_standard_errors) can be obtained using (under some regularity conditions)\n",
    "\n",
    "$$\n",
    "\\hat{\\text{Var}}[\\hat{\\boldsymbol{\\beta}}_{OLS}] = \\left( \\mathbf{X}^\\top\\mathbf{X} \\right)^{-1} \\mathbf{X}^\\top \\hat{\\boldsymbol{\\Omega}}\\mathbf{X} \\left( \\mathbf{X}^\\top\\mathbf{X} \\right)^{-1}\n",
    "$$\n",
    "\n",
    "where $\\hat{\\boldsymbol{\\Omega}} = \\text{Diag}[\\hat{e}_i^2]$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "architectural-generic",
   "metadata": {},
   "source": [
    "## A general framework: m-estimators \n",
    "\n",
    "In financial economics we cannot solely rely on linear regressions, we also need to be able to estimate parameters of different densities or highly non-linear models. \n",
    "\n",
    "Some of the principles observed for OLS can be extended to more general type of estimators namely [m-estimators](https://en.wikipedia.org/wiki/M-estimator) that includes _Non-linear Least Squares (NLS)_ and _Maximum Likelihood Estimation (MLE)_. \n",
    "\n",
    "### Definition of m-estimator\n",
    "\n",
    "An m-estimator $\\hat{\\theta}$ of the $k \\times 1$ parameter vector $\\theta$ minimizes the objective function $Q_n(\\theta)$ that can be written as a sample average\n",
    "\n",
    "$$\n",
    "Q_n(\\theta) = \\frac{1}{n} \\sum_{i=1}^n q(y_i, \\mathbf{x}_i; \\theta)\n",
    "$$\n",
    "where $q(\\cdot)$ is scalar function. We assume independence over $i$.  \n",
    "\n",
    "Clearly, with $q(y_i, \\mathbf{x}_i; \\beta) = (y_i - \\mathbf{x}_i^\\top \\beta)^2$ OLS is an m-estimator!  The m-estimator is computed as the solution to the FOC \n",
    "\n",
    "$$\n",
    "\\left. \\frac{\\partial Q_n(\\theta)}{\\partial \\theta} \\right \\vert _{\\theta = \\hat{\\theta}} = \\frac{1}{n} \\sum_{i=1}^n \\left. \\frac{\\partial q_i(y_i, \\mathbf{x}_i ;\\theta)}{\\partial \\theta} \\right \\vert _{\\theta = \\hat{\\theta}} = \\mathbf{0}\n",
    "$$\n",
    "\n",
    "The $k$ equations with $k$ unknowns will sometimes have an explicit analytical solution, but often we need to use numerical methods to find a solution. \n",
    "\n",
    "### Some comments on properties of m-estimators\n",
    "\n",
    "Generally, it can be an audacious task to derive the properties of m-estimators such as NLS and MLE and it is not the objective of the course. \n",
    "\n",
    "__Consistency__\n",
    "\n",
    "We have to assume that there is a particular data generating process and a corresponding value of $\\theta$, say $\\theta_0$, which generate the data. We need to have that $\\theta_0$ is unique in the sense that other values of $\\theta$ would not correspond to the same data-generating proces ([identification](https://en.wikipedia.org/wiki/Identifiability)). \n",
    "\n",
    "In a linear regression model this holds when $\\mathbf{X}$ has full rank since then \n",
    "\n",
    "$$\n",
    "\\mathbf{x}^\\top \\beta_1 = \\mathbf{x}^\\top \\beta_2\n",
    "$$\n",
    "\n",
    "if and only if $\\beta_1=\\beta_2$. \n",
    "\n",
    "__Limit distribution__\n",
    "\n",
    "As in the case for OLS, the m-estimators that we consider will typically converge asymptotically to a multivariate normal\n",
    "\n",
    "$$\n",
    "\\sqrt{n} (\\hat{\\theta} - \\theta_0) \\to^d N(0, \\mathbf{A}_0^{-1} \\mathbf{B} \\mathbf{A}_0^{-1})\n",
    "$$\n",
    "\n",
    "where \n",
    "\n",
    "$$\n",
    "\\mathbf{A}_0 = \\text{plim} \\frac{1}{n} \\sum_{i=1}^n \\left. \\frac{\\partial^2 q_i(y_i, \\mathbf{x}_i ;\\theta)}{\\partial \\theta \\partial \\theta^\\top} \\right \\vert _{\\theta = \\theta_0} = \\text{lim} \\frac{1}{n} \\sum_{i=1}^n \\text{E} \\left[\\left. \\frac{\\partial^2 q_i(y_i, \\mathbf{x}_i ;\\theta)}{\\partial \\theta \\partial \\theta^\\top} \\right \\vert _{\\theta = \\theta_0} \\right]\n",
    "$$\n",
    "\n",
    "and \n",
    "\n",
    "$$\n",
    "\\mathbf{B}_0 = \\text{plim} \\frac{1}{n} \\sum_{i=1}^n \\left. \\frac{\\partial q_i(y_i, \\mathbf{x}_i ;\\theta)}{\\partial \\theta } \\frac{\\partial q_i(y_i, \\mathbf{x}_i ;\\theta)}{\\partial \\theta^\\top } \\right \\vert _{\\theta = \\theta_0} = \\text{lim} \\frac{1}{n} \\sum_{i=1}^n \\text{E} \\left[\\left. \\frac{\\partial q_i(y_i, \\mathbf{x}_i ;\\theta)}{\\partial \\theta } \\frac{\\partial q_i(y_i, \\mathbf{x}_i ;\\theta)}{\\partial \\theta^\\top } \\right \\vert _{\\theta = \\theta_0} \\right]\n",
    "$$\n",
    "\n",
    "We note that for OLS, we would have \n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\mathbf{A}_0 & =  \\lim \\frac{1}{n} \\text{E} \\left[ \\mathbf{X}^\\top\\mathbf{X} \\right]  =  \\mathbf{M_{xx}} \\\\\n",
    "\\mathbf{B}_0 & = \\lim \\frac{1}{n} \\text{E} \\left[ \\mathbf{X}^\\top \\mathbf{e} \\mathbf{e}^\\top\\mathbf{X}   \\right]  = \\mathbf{M_{x\\Omega x}}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "such that we obtain the asymptotic distribution presented above. \n",
    "\n",
    "We also note that we could use the below estimators when approximating the limit distribution \n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\hat{\\mathbf{A}} & = \\frac{1}{n} \\sum_{i=1}^n \\left. \\frac{\\partial^2 q_i(y_i, \\mathbf{x}_i ;\\theta)}{\\partial \\theta \\partial \\theta^\\top} \\right \\vert _{\\theta = \\hat{\\theta}}  \\\\\n",
    "\\hat{\\mathbf{B}} & = \\frac{1}{n} \\sum_{i=1}^n \\left. \\frac{\\partial q_i(y_i, \\mathbf{x}_i ;\\theta)}{\\partial \\theta } \\frac{\\partial q_i(y_i, \\mathbf{x}_i ;\\theta)}{\\partial \\theta^\\top } \\right \\vert _{\\theta = \\hat{\\theta}}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "characteristic-evaluation",
   "metadata": {},
   "source": [
    "## Maximum likelihood estimation (MLE)\n",
    "\n",
    "[Maximum likelihood estimation](https://en.wikipedia.org/wiki/Maximum_likelihood_estimation) is one of the most widely used estimation methods with a number of diserable properties, e.g. it will be the most efficient estimator among consistent asymptotically normal estimators. \n",
    "\n",
    "The MLE of $\\theta_0$ basically seeks to select the $\\theta$ that maximizes the likelihood of observing the actual sample. The joint density of the random sample $f(\\mathbf{y}, \\mathbf{X}; \\theta)$, which will define as the likelihood function, can under an independence assumption be written as the product of the marginal densities \n",
    "\n",
    "$$\n",
    "L_n (\\theta \\vert \\mathbf{y}, \\mathbf{X}) = f(\\mathbf{y}, \\mathbf{X}; \\theta) = \\prod_{i=1}^n f_{y, \\mathbf{x}_i} (y_i, \\mathbf{x}_i; \\theta)\n",
    "$$\n",
    "\n",
    "Since $\\ln$ is a positive monotone transformation, we can equivalently maximize the log-likelihood function \n",
    "\n",
    "$$\n",
    "\\mathcal{L}_n (\\theta \\vert \\mathbf{y}, \\mathbf{X}) = \\ln L_n (\\theta \\vert \\mathbf{y}, \\mathbf{X}) = \\sum_{i=1}^n \\ln f_{y, \\mathbf{x}_i} (y_i, \\mathbf{x}_i; \\theta)\n",
    "$$\n",
    "\n",
    "\n",
    "### Conditional likelihood\n",
    "\n",
    "We can factorize a density as the product between the conditional and marginal density\n",
    "\n",
    "$$\n",
    "L_n (\\theta \\vert \\mathbf{y}, \\mathbf{X}) = f(\\mathbf{y}, \\mathbf{X}; \\theta) = f(\\mathbf{y} \\vert \\mathbf{X}; \\theta) f(\\mathbf{X}; \\theta)  \n",
    "$$\n",
    "\n",
    "Typically, we will only focus on the conditional density $f(\\mathbf{y} \\vert \\mathbf{X}; \\theta)$ since we are interested in $\\mathbf{y}$ given $\\mathbf{X}$ (we will do this below). It will not be an issue if $\\mathbf{y}$ and $\\mathbf{X}$ depends on different sets of parameters, which often will be a reasonable assumption (but not always). \n",
    "\n",
    "In _time series modelling_, we also often use the notion of a conditional likelihood function since we cannot always apply an independence assumption.  Assume e.g. that $y_t$ depends on $y_{t-1}$ (and no regressors) then we could factorize (using T to indicate time series context)\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "L_T (\\theta \\vert \\mathbf{y}) &= f_{y_0, \\dots, y_T}(y_0, \\dots, y_T; \\theta) \\\\\n",
    "&= f_y(y_0; \\theta) f_{y_1, \\dots, y_T}(y_1, \\dots, y_T; \\theta) \\\\\n",
    "&= f_y(y_0; \\theta) \\prod_{t=1}^T f_{y_t \\vert y_{t-1}}(y_t \\vert y_{t-1}; \\theta)\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "dropping $f_y(y_0; \\theta)$ will result in the conditional likelihood function that is conditional on the starting value. \n",
    "\n",
    "### M-estimator\n",
    "\n",
    "In order to be able to use the results for m-estimators, we just divide the log-likelihood function with $n$\n",
    "\n",
    "$$\n",
    "Q_n(\\theta) = \\frac{1}{n} \\mathcal{L}_n (\\theta) = \\frac{1}{n} \\sum_{i=1}^n \\ln f_{y, \\mathbf{x}_i} (y_i \\vert \\mathbf{x}_i; \\theta)\n",
    "$$\n",
    "\n",
    "__Remember:__ Most optimizers seek to minimize a function so we may need to multiply with minus one and then minimize. \n",
    "\n",
    "__Example: Bernoulli__\n",
    "\n",
    "Assume that we observe a realization of the random sample $Y_1, ...., Y_{n}$ where $Y_i\\sim \\text{Bernoulli}(p), i=1,...,n$  \n",
    "\n",
    "We can write the likelihood function as \n",
    "\n",
    "$$\n",
    "\\begin{equation*}\n",
    "L(p) = \\prod_{i=1}^n f_Y(y_i;p) = \\prod_{i=1}^n p^{y_i}(1-p) ^{1-y_i} = p^{\\sum_{i=1}^n y_i}(1-p)^{\\sum_{i=1}^n (1-y_i)}\n",
    "\\end{equation*}\n",
    "$$\n",
    "\n",
    "We want to maximize with respect to $p$, but we first take the logarithm \n",
    "\n",
    "$$\n",
    "\\begin{equation*}\n",
    "\\ln L(p) = \\ln (p) \\sum_{i=1}^n y_i + \\ln(1-p) \\sum_{i=1}^n (1-y_i)\n",
    "\\end{equation*}\n",
    "$$\n",
    "\n",
    "The first order condition is (take derivative wrt. $p$)\n",
    "\n",
    "$$\n",
    "\\begin{equation*}\n",
    "\\frac{1}{p} \\sum_{i=1}^n y_i - \\frac{1}{1-p} \\left[n - \\sum_{i=1}^n y_i \\right] = 0\n",
    "\\end{equation*}\n",
    "$$\n",
    "\n",
    "such that we obtain the maximum-likelihood estimate\n",
    "\n",
    "$$\n",
    "p_e = \\frac{1}{n}\\sum_{i=1}^n y_i\n",
    "$$\n",
    "\n",
    "Below, we see a simple implementation in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "local-trainer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4499999960279612"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Define log-likelihood function\n",
    "\"\"\"\n",
    "\n",
    "def log_likelihood_function(p, x):\n",
    "    \n",
    "    log_like = np.log(p) * np.sum(x) + np.log(1-p) * np.sum(1-x)\n",
    "    \n",
    "    return log_like\n",
    "\n",
    "\"\"\"\n",
    "Generate data\n",
    "\"\"\"\n",
    "np.random.seed(5)\n",
    "bernoulli_data = np.random.binomial(1,0.5,size=20)\n",
    "\n",
    "\"\"\"\n",
    "Minimize negative of log-likelihood\n",
    "\"\"\"\n",
    "neg_log_lik = lambda p: -log_likelihood_function(p, bernoulli_data)\n",
    "\n",
    "res = minimize(neg_log_lik, 0.5, bounds={(0.00001,0.99999)})\n",
    "res.x[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "christian-person",
   "metadata": {},
   "source": [
    "### Information matrix equality\n",
    " \n",
    "The [information matrix](https://en.wikipedia.org/wiki/Fisher_information) can equivalently be written as \n",
    "\n",
    "$$\n",
    "I(\\theta) = -\\text{E} \\left[ \\left. \\frac{\\partial^2 \\mathcal{L}_n (\\theta)}{\\partial \\theta \\partial \\theta^\\top} \\right \\vert_{\\theta = \\theta_0}\\right] = \\text{E} \\left[ \\left. \\frac{\\partial \\mathcal{L}_n (\\theta)}{\\partial \\theta } \\frac{\\partial \\mathcal{L}_n (\\theta)}{\\partial \\theta^\\top } \\right \\vert_{\\theta = \\theta_0}\\right]\n",
    "$$\n",
    "\n",
    "### Asymptotic distribution \n",
    "\n",
    "The Information matrix equality implies that $-\\mathbf{A}_0 = \\mathbf{B}_0$ such that $\\mathbf{A}_0 ^{-1}\\mathbf{B}_0 \\mathbf{A}_0 ^{-1} =  \\mathbf{B}_0 ^{-1}=  -\\mathbf{A}_0^{-1}$. \n",
    "\n",
    "Using the results for m-estimators, we have \n",
    "\n",
    "$$\n",
    "\\sqrt{n} (\\hat{\\theta}_{MLE} - \\theta_0) \\to^d N(0, -\\mathbf{A}_0^{-1})\n",
    "$$\n",
    "\n",
    "or alternatively written as \n",
    "\n",
    "$$\n",
    "\\hat{\\theta}_{MLE} \\sim ^a N\\left(\\theta_0, -\\left(\\text{E} \\left[ \\left. \\frac{\\partial^2 \\mathcal{L}_n (\\theta)}{\\partial \\theta \\partial \\theta^\\top} \\right \\vert_{\\theta = \\theta_0}\\right] \\right)^{-1}\\right)\n",
    "$$\n",
    "\n",
    "Note that \n",
    "\n",
    "$$\n",
    "V(\\theta) = -\\left(\\text{E} \\left[ \\left. \\frac{\\partial^2 \\mathcal{L}_n (\\theta)}{\\partial \\theta \\partial \\theta^\\top} \\right \\vert_{\\theta = \\theta_0}\\right] \\right)^{-1}\n",
    "$$\n",
    "\n",
    "corresponds to Cramér-Rao's lower bound such that the MLE is the most efficient estimator among consistent and asympotically normal estimators. \n",
    "\n",
    "__Note:__ To avoid confusion we may note that \n",
    "\n",
    "$$\n",
    "-\\left(\\text{E} \\left[ \\left. \\frac{\\partial^2 \\mathcal{L}_n (\\theta)}{\\partial \\theta \\partial \\theta^\\top} \\right \\vert_{\\theta = \\theta_0}\\right] \\right)^{-1} = -\\left(\\text{E} \\left[ \\left. \\sum_{i=1}^n \\frac{\\partial^2 \\ln f_y(y_i; \\theta) }{\\partial \\theta \\partial \\theta^\\top} \\right \\vert_{\\theta = \\theta_0}\\right] \\right)^{-1} = - \\left(n\\text{E} \\left[ \\left.  \\frac{\\partial^2 \\ln f_y(y_i; \\theta) }{\\partial \\theta \\partial \\theta^\\top} \\right \\vert_{\\theta = \\theta_0}\\right] \\right)^{-1}  \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "innovative-porcelain",
   "metadata": {},
   "source": [
    "## Non-linear Least Squares (NLS)\n",
    "\n",
    "A non-linear regression model specifies the conditional mean as \n",
    "\n",
    "$$\n",
    "\\text{E}[y_i \\vert \\mathbf{x}_i] = g(\\mathbf{x}_i; \\theta)\n",
    "$$\n",
    "\n",
    "or equivalently written as (assuming that $\\text{E}[\\mathbf{e} \\vert \\mathbf{x}] = 0$)\n",
    "\n",
    "$$\n",
    "y_i = g(\\mathbf{x}_i; \\theta) + e_i\n",
    "$$\n",
    "\n",
    "Clearly, linear regression is the special case $g(\\mathbf{x}_i; \\beta) = \\mathbf{x}_i^\\top \\beta$. \n",
    "\n",
    "The NLS estimator will minimize the sum of squared residuals or minimize (we can scale with $1/2$ without loss of generality)\n",
    "\n",
    "$$\n",
    "Q_n(\\theta) = - \\frac{1}{2n} \\sum_{i=1}^n (y_i - g(\\mathbf{x}_i; \\theta))^2\n",
    "$$\n",
    "\n",
    "The FOC gives us \n",
    "\n",
    "$$\n",
    "\\frac{\\partial Q_n(\\theta)}{\\partial \\theta} = \\frac{1}{n} \\sum_{i=1}^n \\frac{\\partial g(\\mathbf{x}_i; \\theta)}{\\partial \\theta} (y_i - g(\\mathbf{x}_i; \\theta)) = \\mathbf{0}\n",
    "$$\n",
    "\n",
    "or more compactly using matrix notation \n",
    "\n",
    "$$\n",
    "\\frac{\\partial Q_n(\\theta)}{\\partial \\theta} = \\frac{1}{n}\\frac{\\partial \\mathbf{g}^\\top}{\\partial \\theta} (\\mathbf{y}- \\mathbf{g})\n",
    "$$\n",
    "\n",
    "For consistency of the NLS estimator, it is crucial that the mean is specified correctly. \n",
    "\n",
    "Assuming a covariance matrix for the errors $\\text{E}[\\mathbf{e} \\mathbf{e}^\\top \\vert \\mathbf{X}] = \\boldsymbol{\\Omega}_0$\n",
    "and under regularity conditions, it will be the case that \n",
    "\n",
    "$$\n",
    "\\sqrt{n} (\\hat{\\theta}_{NLS} - \\theta_0) \\to^d N(0, \\mathbf{A}_0^{-1} \\mathbf{B}_0 \\mathbf{A}_0^{-1})\n",
    "$$\n",
    "\n",
    "with \n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\mathbf{A}_0 &= \\text{plim} \\left. \\frac{1}{n} \\frac{\\partial \\mathbf{g}^\\top}{\\partial \\theta} \\frac{\\partial \\mathbf{g}}{\\partial \\theta^\\top}  \\right \\vert_{\\theta = \\theta_0}\\\\\n",
    "\\mathbf{B}_0 &= \\text{plim} \\left. \\frac{1}{n} \\frac{\\partial \\mathbf{g}^\\top}{\\partial \\theta} \\boldsymbol{\\Omega}_0 \\frac{\\partial \\mathbf{g}}{\\partial \\theta^\\top} \\right \\vert_{\\theta = \\theta_0}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "A reasonable estimator for $\\mathbf{A}_0$ is \n",
    "\n",
    "$$\n",
    "\\hat{\\mathbf{A}} = \\left. \\frac{1}{n} \\frac{\\partial \\mathbf{g}^\\top}{\\partial \\theta} \\frac{\\partial \\mathbf{g}}{\\partial \\theta^\\top}\\right \\vert_{\\theta = \\hat{\\theta}_{NLS}}\n",
    "$$\n",
    "\n",
    "For $\\mathbf{B}_0$ it depends (just as in the OLS case) on the assumption we can make about $\\boldsymbol{\\Omega}_0$. Assuming independence implies that $\\boldsymbol{\\Omega}_0$ must be a diagonal matrix. If homoskedasticity of the error term can be assumed then \n",
    "\n",
    "$$\n",
    "\\sqrt{n} (\\hat{\\theta}_{NLS} - \\theta_0) \\to^d N(0, \\sigma^2 \\mathbf{A}_0^{-1})\n",
    "$$\n",
    "\n",
    "and we just need to estimate $\\sigma^2$ using the sample variance. If we allow for heteroskedasticity, we can estimate \n",
    "\n",
    "$$\n",
    "\\hat{\\mathbf{B}} = \\left. \\frac{1}{n} \\frac{\\partial \\mathbf{g}^\\top}{\\partial \\theta} \\hat{\\boldsymbol{\\Omega}}\\frac{\\partial \\mathbf{g}}{\\partial \\theta^\\top}\\right \\vert_{\\theta = \\hat{\\theta}_{NLS}}\n",
    "$$\n",
    "\n",
    "where $\\hat{\\boldsymbol{\\Omega}} = \\text{Diag}[\\hat{e}_i^2]$. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "turkish-vulnerability",
   "metadata": {},
   "source": [
    "## Application: Exponential distribution \n",
    "\n",
    "The [exponential density](https://en.wikipedia.org/wiki/Exponential_distribution) is given by\n",
    "\n",
    "$$\n",
    "f_Y(y) = \\lambda e^{-\\lambda y}, \\; y > 0, \\; \\lambda > 0\n",
    "$$\n",
    "\n",
    "The mean and variance is respectively $1/\\lambda$ and $1/\\lambda^2$. The exponential distribution can be used to describe the time for a continuous process to change state or for an event to occur, e.g. time between roadkills on a given road. \n",
    "\n",
    "Below we plot the density of a exponential density (with the above parameterization) assuming $\\lambda = 12$. On average, we will wait $1/12$ time periods for one event to occur (one month if $y$ is measured in years). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "suffering-affair",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lam = 12.0\n",
    "y_values = np.linspace(0.001, 2.0, 1000)\n",
    "pdf_values = stats.expon.pdf(y_values, scale = 1 / lam)\n",
    "\n",
    "\"\"\"\n",
    "Plotting\n",
    "\"\"\"\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "ax.plot(y_values, pdf_values, color=\"blue\")\n",
    "ax.set_xlabel('$y$');\n",
    "ax.set_ylabel('$f_Y(y)$');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "threatened-transaction",
   "metadata": {},
   "source": [
    "We may introduce explanatory variables by specifying \n",
    "\n",
    "$$\n",
    "\\lambda = e^{\\mathbf{x}^\\top \\beta} \n",
    "$$\n",
    "\n",
    "ensuring $\\lambda > 0$ and specifying the conditional mean as \n",
    "\n",
    "$$\n",
    "\\text{E}[y \\vert \\mathbf{x}] = e^{-\\mathbf{x}^\\top \\beta}\n",
    "$$\n",
    "\n",
    "Assume that we observe a realization of a iid random sample $y_i, \\mathbf{x}_i$, $i = 1, ... n$. \n",
    "\n",
    "### The MLE \n",
    "\n",
    "The (conditional) log-likehood function can be written\n",
    "\n",
    "$$\n",
    "\\mathcal{L}_n (\\beta) =  \\sum_{i=1}^n  \\left[ \\mathbf{x}_i^\\top \\beta - e^{\\mathbf{x}_i^\\top \\beta} y_i\\right]\n",
    "$$\n",
    "\n",
    "with the FOC \n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\mathcal{L}_n (\\beta)}{\\partial \\beta} =  \\sum_{i=1}^n  \\left[ \\mathbf{x}_i  - \\mathbf{x}_i e^{\\mathbf{x}_i^\\top \\beta} y_i\\right] = \\sum_{i=1}^n  \\mathbf{x}_i\\left[ 1  - e^{\\mathbf{x}_i^\\top \\beta} y_i\\right] = \\mathbf{0}\n",
    "$$\n",
    "\n",
    "To obtain the variance of the MLE estimator, it will be useful to note that (using the more general notation of m-estimators)\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{1}{n} \\sum_{i=1}^n  \\frac{\\partial^2 q_i(y_i, \\mathbf{x}_i ;\\beta)}{\\partial \\beta \\partial \\beta^\\top} &=  \\frac{1}{n} \\sum_{i=1}^n -\\mathbf{x}_i \\mathbf{x}_i^\\top e^{\\mathbf{x}_i^\\top \\beta} y_i\\\\\n",
    "\\frac{1}{n} \\sum_{i=1}^n \\frac{\\partial q_i(y_i, \\mathbf{x}_i ;\\beta)}{\\partial \\beta } \\frac{\\partial q_i(y_i, \\mathbf{x}_i ;\\beta)}{\\partial \\beta^\\top }  &=      \\frac{1}{n} \\sum_{i=1}^n \\mathbf{x}_i \\mathbf{x}_i^\\top \\left[1 - e^{\\mathbf{x}_i^\\top \\beta} y_i \\right]^2\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "\n",
    "### The NLS estimator\n",
    "\n",
    "A non-linear least squares estimator can be implemented by estimating \n",
    "\n",
    "$$\n",
    "y_i = e^{\\mathbf{x}_i^\\top \\beta} + e_i\n",
    "$$\n",
    "\n",
    "We also note that the error term is heteroskedastic since $\\text{Var}[y_i] = 1 / [e^{\\mathbf{x}_i^\\top \\beta}]^2$. Our FOC reads\n",
    "\n",
    "$$\n",
    "\\frac{1}{n} \\sum_{i=1}^n (y_i - e^{\\mathbf{x}_i^\\top \\beta})e^{\\mathbf{x}_i^\\top \\beta}\\mathbf{x}_i = \\mathbf{0}\n",
    "$$\n",
    "\n",
    "For calculating variance, we note that (using the notation for NLS above)\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{1}{n} \\sum_{i=1}^n \\frac{\\partial g_i(y_i, \\mathbf{x}_i ;\\beta)}{\\partial \\beta } \\frac{\\partial g_i(y_i, \\mathbf{x}_i ;\\beta)}{\\partial \\beta^\\top }  &= \\frac{1}{n} \\sum_{i=1}^n e^{2\\mathbf{x}_i^\\top \\beta}\\mathbf{x}_i \\mathbf{x}_i^\\top \\\\\n",
    "\\frac{1}{n} \\sum_{i=1}^n \\sigma_i^2 \\frac{\\partial g_i(y_i, \\mathbf{x}_i ;\\beta)}{\\partial \\beta } \\frac{\\partial g_i(y_i, \\mathbf{x}_i ;\\beta)}{\\partial \\beta^\\top }  &=  \\frac{1}{n} \\sum_{i=1}^n e^{-2\\mathbf{x}_i^\\top \\beta} e^{2\\mathbf{x}_i^\\top \\beta}\\mathbf{x}_i \\mathbf{x}_i^\\top = \\frac{1}{n} \\sum_{i=1}^n \\mathbf{x}_i \\mathbf{x}_i^\\top\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lasting-interview",
   "metadata": {},
   "source": [
    "### Simulating data and implementing estimators\n",
    "\n",
    "We consider 10,000 iid draws from the data generating process\n",
    "\n",
    "$$\n",
    "y \\sim \\text{Exp}(\\beta_1 + \\beta_2 x)\n",
    "$$\n",
    "\n",
    "with $x \\sim N(1, 1)$ and $(\\beta_1, \\beta_2) = (1, -2)$. \n",
    "\n",
    "Below we implement the (negative) log-likelhood function and minimize it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "promotional-azerbaijan",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Generate data\n",
    "\"\"\"\n",
    "n_sim = 10000\n",
    "\n",
    "beta1 = 1.0\n",
    "beta2 = -2.0\n",
    "beta = np.array([beta1, beta2])\n",
    "\n",
    "x_data = np.random.normal(loc=1, scale=1, size=n_sim)\n",
    "x_data = np.c_[np.ones(n_sim), x_data]\n",
    "y_data = np.random.exponential(scale = 1 / np.exp(x_data @ beta), size=n_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "sunset-drill",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.97401107, -1.99806724])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Define log-likelihood function (negative)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def log_likelihood_function(beta, y, x, individual=False):\n",
    "    \n",
    "    log_like = x @ beta - np.exp(x @ beta) * y\n",
    "    \n",
    "    if individual: \n",
    "        return -log_like\n",
    "    else:\n",
    "        return -np.sum(log_like)\n",
    "\n",
    "\"\"\"\n",
    "Minimize negative log-likelihood \n",
    "\"\"\"\n",
    "res_dict = {}\n",
    "res_dict['MLE'] = {}\n",
    "\n",
    "res = minimize(log_likelihood_function, [0.5, 0.5], args=(y_data, x_data))\n",
    "res_dict['MLE']['beta1'] = res.x[0]\n",
    "res_dict['MLE']['beta2'] = res.x[1]\n",
    "params_mle = res.x\n",
    "params_mle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "classified-savage",
   "metadata": {},
   "source": [
    "We have several different options when calculating the variance of the estimator. In this particular model, we know that \n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\text{E}\\left[\\frac{1}{n} \\sum_{i=1}^n \\mathbf{x}_i \\mathbf{x}_i^\\top \\left[1 - e^{\\mathbf{x}_i^\\top \\beta} y_i \\right]^2 \\right] &= \\frac{1}{n}\\sum_{i=1}^n \\text{E}\\left[\\mathbf{x}_i \\mathbf{x}_i^\\top \\left[1 - e^{\\mathbf{x}_i^\\top \\beta} y_i \\right]^2 \\right] \\\\\n",
    "        & = \\frac{1}{n}\\sum_{i=1}^n \\text{E}\\left[\\mathbf{x}_i \\mathbf{x}_i^\\top \\right]\\\\\n",
    "\\text{E}\\left[ \\frac{1}{n} \\sum_{i=1}^n -\\mathbf{x}_i \\mathbf{x}_i^\\top e^{\\mathbf{x}_i^\\top \\beta} y_i \\right] &= -\\frac{1}{n}\\sum_{i=1}^n \\text{E}\\left[\\mathbf{x}_i \\mathbf{x}_i^\\top \\right]\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Given our assumptions about $x$, we know that \n",
    "\n",
    "$$\n",
    "\\text{E}\\left[\\mathbf{x}_i \\mathbf{x}_i^\\top \\right] = \\text{E}\\left[\\begin{bmatrix} 1 \\\\ x_i \\end{bmatrix} \\begin{bmatrix} 1 & x_i \\end{bmatrix} \\right] = \\text{E}\\left[\\begin{bmatrix} 1 & x_i \\\\ x_i & x_i^2 \\end{bmatrix} \\right] = \\begin{bmatrix} 1 & 1 \\\\ 1 & 2 \\end{bmatrix} \n",
    "$$\n",
    "\n",
    "such that the variance is given by\n",
    "\n",
    "$$\n",
    "\\text{Var}[\\hat{\\beta}] = - \\left[-n \\text{E}\\left[\\mathbf{x}_i \\mathbf{x}_i^\\top \\right]\\right]^{-1}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "relevant-coalition",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.0002, -0.0001],\n",
       "       [-0.0001,  0.0001]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_xx_true = np.array([[1, 1], [1, 2]])\n",
    "param_mle_cov_true = np.linalg.inv(n_sim*exp_xx_true)\n",
    "\n",
    "res_dict['MLE']['std1_true'] = np.sqrt(param_mle_cov_true[0,0])\n",
    "res_dict['MLE']['std2_true'] = np.sqrt(param_mle_cov_true[1,1])\n",
    "\n",
    "# print covariance matrix of parameter estimator \n",
    "param_mle_cov_true"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "republican-yorkshire",
   "metadata": {},
   "source": [
    "Generally, we observe real data, i.e. we do not know the true data generating process, such that we need to estimate the variance of the estimator. We need to evaluate the below expression at the MLE estimate. \n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{1}{n} \\sum_{i=1}^n  \\frac{\\partial^2 q_i(y_i, \\mathbf{x}_i ;\\beta)}{\\partial \\beta \\partial \\beta^\\top} &= \\frac{1}{n} \\sum_{i=1}^n -\\mathbf{x}_i \\mathbf{x}_i^\\top e^{\\mathbf{x}_i^\\top \\beta} y_i \\\\\n",
    "\\frac{1}{n} \\sum_{i=1}^n \\frac{\\partial q_i(y_i, \\mathbf{x}_i ;\\beta)}{\\partial \\beta } \\frac{\\partial q_i(y_i, \\mathbf{x}_i ;\\beta)}{\\partial \\beta^\\top }  &=     \\frac{1}{n} \\sum_{i=1}^n \\mathbf{x}_i \\mathbf{x}_i^\\top \\left[1 - e^{\\mathbf{x}_i^\\top \\beta} y_i \\right]^2\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "correct-spencer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 2)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "wooden-clearance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 2, 2)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.einsum('ji,jk->jik',x_data, x_data).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "civic-movie",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Gradient \n",
    "\"\"\"\n",
    "\n",
    "def outer_gradient(beta, x, y): \n",
    "    \n",
    "    return np.sum(((1 - np.exp(x @ beta) * y)**2)[:, None, None] * np.einsum('ji,jk->jik',x, x), axis=0)\n",
    "\n",
    "def outer_gradient_alternative(beta, x, y): \n",
    "    \n",
    "    x_new = (1 - np.exp(x @ beta) * y)[:, None] * x\n",
    "    \n",
    "    return x_new.T @ x_new\n",
    "\n",
    "\"\"\"\n",
    "Hessian \n",
    "\"\"\"\n",
    "\n",
    "def hessian(beta, x, y): \n",
    "    \n",
    "    return -np.sum((np.exp(x_data @ beta) * y)[:, None, None] * \n",
    "                   np.einsum('ji,jk->jik',x, x), axis=0) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "institutional-constitution",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10117.42366054, 10574.5681502 ],\n",
       "       [10574.5681502 , 21671.14588083]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outer_gradient(params_mle, x_data, y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "metallic-drunk",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10117.42366054, 10574.5681502 ],\n",
       "       [10574.5681502 , 21671.14588083]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outer_gradient_alternative(params_mle, x_data, y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "executed-clinic",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = hessian(params_mle, x_data, y_data)\n",
    "B = outer_gradient(params_mle, x_data, y_data)\n",
    "\n",
    "param_mle_cov_A = np.linalg.inv(-A)\n",
    "res_dict['MLE']['std1_A'] = np.sqrt(param_mle_cov_A[0,0])\n",
    "res_dict['MLE']['std2_A'] = np.sqrt(param_mle_cov_A[1,1])\n",
    "\n",
    "param_mle_cov_B = np.linalg.inv(B)\n",
    "res_dict['MLE']['std1_B'] = np.sqrt(param_mle_cov_B[0,0])\n",
    "res_dict['MLE']['std2_B'] = np.sqrt(param_mle_cov_B[1,1])\n",
    "\n",
    "param_mle_cov_sandwich = np.linalg.inv(A) @ B @ np.linalg.inv(A)\n",
    "res_dict['MLE']['std1_SW'] = np.sqrt(param_mle_cov_sandwich[0,0])\n",
    "res_dict['MLE']['std2_SW'] = np.sqrt(param_mle_cov_sandwich[1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "floppy-amino",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.97106342e-04, -9.72262108e-05],\n",
       "       [-9.72262108e-05,  9.73462293e-05]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# covariance matrix based on A\n",
    "param_mle_cov_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "nasty-thousand",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.01714636e-04, -9.84278902e-05],\n",
       "       [-9.84278902e-05,  9.41727975e-05]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# covariance matrix based on B\n",
    "param_mle_cov_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "concerned-algebra",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.92627082e-04, -9.61372903e-05],\n",
       "       [-9.61372903e-05,  1.00833165e-04]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# covariance matrix based on A^{-1}BA^{-1} \"Sandwich formula\"\n",
    "param_mle_cov_sandwich"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quiet-alabama",
   "metadata": {},
   "source": [
    "The above calculations assume that we have derived the formula for \"A\" and \"B\" such that we \"just\" need to evaluate at the MLE estimate. \n",
    "\n",
    "However, it may be a tedious task. A common approach is to use numerical derivatives or other tools to calculate \"A\" and \"B\". Below we use the `statsmodels.tools.numdiff` package.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "champion-impossible",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = approx_fprime(params_mle, log_likelihood_function, args=(y_data, x_data, True))\n",
    "B_approx = scores.T @ scores  #np.sum(np.einsum('ji,jk->jik', scores, scores), axis=0)\n",
    "\n",
    "A_approx = -approx_hess(params_mle, log_likelihood_function, args=(y_data, x_data))\n",
    "\n",
    "param_mle_cov_A_num = np.linalg.inv(-A_approx)\n",
    "res_dict['MLE']['std1_A_num'] = np.sqrt(param_mle_cov_A_num[0,0])\n",
    "res_dict['MLE']['std2_A_num'] = np.sqrt(param_mle_cov_A_num[1,1])\n",
    "\n",
    "param_mle_cov_B_num = np.linalg.inv(B_approx)\n",
    "res_dict['MLE']['std1_B_num'] = np.sqrt(param_mle_cov_B_num[0,0])\n",
    "res_dict['MLE']['std2_B_num'] = np.sqrt(param_mle_cov_B_num[1,1])\n",
    "\n",
    "param_mle_cov_sandwich_num = np.linalg.inv(A_approx) @ B_approx @ np.linalg.inv(A_approx)\n",
    "res_dict['MLE']['std1_SW_num'] = np.sqrt(param_mle_cov_sandwich_num[0,0])\n",
    "res_dict['MLE']['std2_SW_num'] = np.sqrt(param_mle_cov_sandwich_num[1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "worst-amber",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.97106339e-04, -9.72262037e-05],\n",
       "       [-9.72262037e-05,  9.73462184e-05]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# covariance matrix based on A\n",
    "param_mle_cov_A_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "sexual-breakdown",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.01714633e-04, -9.84278872e-05],\n",
       "       [-9.84278872e-05,  9.41727928e-05]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# covariance matrix based on B\n",
    "param_mle_cov_B_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "temporal-bolivia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.92627077e-04, -9.61372789e-05],\n",
       "       [-9.61372789e-05,  1.00833147e-04]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# covariance matrix based on A^{-1}BA^{-1} \"Sandwich formula\"\n",
    "param_mle_cov_sandwich_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "engaging-naples",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MLE': {'beta1': 0.9740110716297232,\n",
       "  'beta2': -1.9980672366953254,\n",
       "  'std1_true': 0.01414213562373095,\n",
       "  'std2_true': 0.01,\n",
       "  'std1_A': 0.01403945661528078,\n",
       "  'std2_A': 0.009866419273197263,\n",
       "  'std1_B': 0.014202627791302073,\n",
       "  'std2_B': 0.00970426697414618,\n",
       "  'std1_SW': 0.013879015879292363,\n",
       "  'std2_SW': 0.010041571839532224,\n",
       "  'std1_A_num': 0.01403945649079017,\n",
       "  'std2_A_num': 0.009866418722632993,\n",
       "  'std1_B_num': 0.014202627693499578,\n",
       "  'std2_B_num': 0.009704266731077105,\n",
       "  'std1_SW_num': 0.01387901572271639,\n",
       "  'std2_SW_num': 0.010041570961713316}}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enhanced-frame",
   "metadata": {},
   "source": [
    "We have specified the model correctly and have lots of data, so it is no surprice that maximum likelihood performs well. Due to the information matrix equality, then using different variance estimators gives us very similar results. \n",
    "\n",
    "Next, we define the NLS objective and minimze it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "suitable-subdivision",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_nls(beta, y, x, individual=False): \n",
    "    \n",
    "    loss = np.square(y - np.exp(-x @ beta))\n",
    "    \n",
    "    if individual: \n",
    "        return loss\n",
    "    else:\n",
    "        return np.sum(loss) / len(y)\n",
    "    \n",
    "def foc_nls(beta, y, x): \n",
    "    \n",
    "    der = (y - np.exp(-x @ beta)) * np.exp(-x @ beta) @ x\n",
    "    \n",
    "\n",
    "    return np.sum(der)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "powerful-proof",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.01055237, -1.68355577])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_dict['NLS'] = {}\n",
    "\n",
    "res = minimize(objective_nls, [1.0, -2.0], args=(y_data, x_data, False))\n",
    "res_dict['NLS']['beta1'] = res.x[0]\n",
    "res_dict['NLS']['beta2'] = res.x[1]\n",
    "params_nls = res.x\n",
    "params_nls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "present-setup",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      fun: 4869.557678276123\n",
       " hess_inv: array([[ 3.47361311e-04, -1.11168663e-04],\n",
       "       [-1.11168663e-04,  4.18734825e-05]])\n",
       "      jac: array([0., 0.])\n",
       "  message: 'Optimization terminated successfully.'\n",
       "     nfev: 57\n",
       "      nit: 11\n",
       "     njev: 19\n",
       "   status: 0\n",
       "  success: True\n",
       "        x: array([-0.01055237, -1.68355577])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "trained-military",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x_data[:, 1], y_data)\n",
    "plt.scatter(x_data[:, 1],  np.exp(-x_data @ params_nls));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "entire-extra",
   "metadata": {},
   "source": [
    "Next step is to calculate the variance of the NLS estimator. Again, we can either use the exact analytical expressions or use numerical derivatives. We consider the analytical derivatives. \n",
    "\n",
    "We implement \n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{1}{n} \\sum_{i=1}^n \\frac{\\partial g_i(y_i, \\mathbf{x}_i ;\\beta)}{\\partial \\beta } \\frac{\\partial g_i(y_i, \\mathbf{x}_i ;\\beta)}{\\partial \\beta^\\top }  &= \\frac{1}{n} \\sum_{i=1}^n e^{2\\mathbf{x}_i^\\top \\beta}\\mathbf{x}_i \\mathbf{x}_i^\\top \\\\\n",
    "\\frac{1}{n} \\sum_{i=1}^n \\sigma_i^2 \\frac{\\partial g_i(y_i, \\mathbf{x}_i ;\\beta)}{\\partial \\beta } \\frac{\\partial g_i(y_i, \\mathbf{x}_i ;\\beta)}{\\partial \\beta^\\top }  &=  \\frac{1}{n} \\sum_{i=1}^n e^{-2\\mathbf{x}_i^\\top \\beta} e^{2\\mathbf{x}_i^\\top \\beta}\\mathbf{x}_i \\mathbf{x}_i^\\top = \\frac{1}{n} \\sum_{i=1}^n \\mathbf{x}_i \\mathbf{x}_i^\\top\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "certain-brass",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_scores_g(beta, y, x):\n",
    "    return np.exp(-x @ beta)[:, None] * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "married-mercury",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_g = calculate_scores_g(params_nls, y_data, x_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "tight-chicken",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = scores_g.T @ scores_g\n",
    "B = scores_g.T @ np.diag(np.exp(-2*x_data @ params_nls)) @ scores_g\n",
    "B_alt = scores_g.T @ np.diag((y_data - np.exp(-x_data @ params_nls) )**2) @ scores_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "weird-christmas",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_nls_cov_A_num = np.linalg.inv(A) #<-- understates variance\n",
    "res_dict['NLS']['std1_A_num'] = np.sqrt(param_nls_cov_A_num[0,0])\n",
    "res_dict['NLS']['std2_A_num'] = np.sqrt(param_nls_cov_A_num[1,1])\n",
    "\n",
    "param_nls_cov_B_num = np.linalg.inv(B) #<-- understates variance\n",
    "res_dict['NLS']['std1_B_num'] = np.sqrt(param_nls_cov_B_num[0,0])\n",
    "res_dict['NLS']['std2_B_num'] = np.sqrt(param_nls_cov_B_num[1,1])\n",
    "\n",
    "param_nls_cov_sandwich_num = np.linalg.inv(A) @ B @ np.linalg.inv(A) #<-- valid estimator due to heteroskedasticity\n",
    "res_dict['NLS']['std1_SW_num'] = np.sqrt(param_nls_cov_sandwich_num[0,0])\n",
    "res_dict['NLS']['std2_SW_num'] = np.sqrt(param_nls_cov_sandwich_num[1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "frank-cleveland",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.92827684e-07, -1.51848806e-07],\n",
       "       [-1.51848806e-07,  4.02589040e-08]])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_nls_cov_A_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "chronic-cable",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.41789204e-12, -9.88004838e-13],\n",
       "       [-9.88004838e-13,  2.21589754e-13]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_nls_cov_B_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "appreciated-investment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.66421383, -0.21151309],\n",
       "       [-0.21151309,  0.06770524]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_nls_cov_sandwich_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "powerful-pontiac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MLE': {'beta1': 0.9740110716297232,\n",
       "  'beta2': -1.9980672366953254,\n",
       "  'std1_true': 0.01414213562373095,\n",
       "  'std2_true': 0.01,\n",
       "  'std1_A': 0.01403945661528078,\n",
       "  'std2_A': 0.009866419273197263,\n",
       "  'std1_B': 0.014202627791302073,\n",
       "  'std2_B': 0.00970426697414618,\n",
       "  'std1_SW': 0.013879015879292363,\n",
       "  'std2_SW': 0.010041571839532224,\n",
       "  'std1_A_num': 0.01403945649079017,\n",
       "  'std2_A_num': 0.009866418722632993,\n",
       "  'std1_B_num': 0.014202627693499578,\n",
       "  'std2_B_num': 0.009704266731077105,\n",
       "  'std1_SW_num': 0.01387901572271639,\n",
       "  'std2_SW_num': 0.010041570961713316},\n",
       " 'NLS': {'beta1': -0.010552372548120458,\n",
       "  'beta2': -1.6835557693354248,\n",
       "  'std1_A_num': 0.0007699530400592398,\n",
       "  'std2_A_num': 0.0002006462159442804,\n",
       "  'std1_B_num': 2.1018782161332814e-06,\n",
       "  'std2_B_num': 4.7073320884580154e-07,\n",
       "  'std1_SW_num': 0.8149931476023656,\n",
       "  'std2_SW_num': 0.2602023114070647}}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aggregate-nitrogen",
   "metadata": {},
   "source": [
    "## Estimation using SciPy\n",
    "\n",
    "`scipy` provides MLE methods for implemented distributions (see e.g. [here](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.rv_continuous.fit.html)). For instance, we can fit the parameters of a normal distribution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "center-bouquet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLE mu: 5.004952883513748\n",
      "MLE std: 1.0037262291246467\n",
      "\n",
      "SciPy mu: 5.004952883513748\n",
      "SciPy std: 1.0037262291246467\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Simulate Normal data and estimate parameters\n",
    "\"\"\"\n",
    "\n",
    "num_sim = 10000\n",
    "sigma = 1\n",
    "mu = 5\n",
    "\n",
    "\n",
    "norm_data = np.random.normal(loc=mu, scale=sigma, size=num_sim)\n",
    "\n",
    "# Known MLE \n",
    "mu_est = np.mean(norm_data)\n",
    "variance_est = np.var(norm_data)\n",
    "sigma_est = np.sqrt(variance_est)\n",
    "\n",
    "print(\"MLE mu: \" + str(mu_est))\n",
    "print(\"MLE std: \" + str(sigma_est) + \"\\n\")\n",
    "\n",
    "# fit using SciPy\n",
    "mu_scipy_est, sigma_scipy_est = stats.norm.fit(norm_data)\n",
    "\n",
    "print(\"SciPy mu: \" + str(mu_scipy_est))\n",
    "print(\"SciPy std: \" + str(sigma_scipy_est))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regulation-bosnia",
   "metadata": {},
   "source": [
    "## Estimation using Statsmodels\n",
    "\n",
    "`scipy` provides a quick MLE implementation for different distributions, but may not be applicable for more complicated problem. \n",
    "\n",
    "`statsmodels` provides a framework for implementing generic MLE estimators (see [docs](https://www.statsmodels.org/dev/examples/notebooks/generated/generic_mle.html)). Let us try to implement our exponential model using `statsmodels`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "healthy-scholarship",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 2.021593\n",
      "         Iterations: 52\n",
      "         Function evaluations: 100\n",
      "                             Exponential Results                              \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   Log-Likelihood:                -20216.\n",
      "Model:                    Exponential   AIC:                         4.044e+04\n",
      "Method:            Maximum Likelihood   BIC:                         4.045e+04\n",
      "Date:                Mon, 11 Oct 2021                                         \n",
      "Time:                        16:19:02                                         \n",
      "No. Observations:               10000                                         \n",
      "Df Residuals:                    9998                                         \n",
      "Df Model:                           1                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.9741      0.014     69.383      0.000       0.947       1.002\n",
      "x1            -1.9981      0.010   -202.518      0.000      -2.017      -1.979\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.base.model import GenericLikelihoodModel\n",
    "\n",
    "# overwrite loglikelihood function in Generic Likelihood Class\n",
    "class Exponential(GenericLikelihoodModel):\n",
    "    \n",
    "    def loglike(self, params):\n",
    "        exog = self.exog\n",
    "        endog = self.endog\n",
    "        return (exog @ params - np.exp(exog @ params) * endog).sum()\n",
    "\n",
    "# fit models\n",
    "exponential_fit = Exponential(y_data, x_data).fit()\n",
    "\n",
    "# print results\n",
    "print(exponential_fit.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "respiratory-drill",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.97401107, -1.99806724])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Our previous estimates\n",
    "\"\"\"\n",
    "\n",
    "params_mle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hourly-passion",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "## Books\n",
    "\n",
    " [Microeconometrics: Methods and Applications, Cameron and Trivedi (2005)](https://www.cambridge.org/highereducation/books/microeconometrics/982158DE989697607C858068ED05C7B1#overview)\n",
    " \n",
    " [Econometric Analysis 7th edition, William H. Greene (2012)](https://www.amazon.com/Econometric-Analysis-7th-William-Greene/dp/0131395386)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_for_fin_econ",
   "language": "python",
   "name": "python_for_fin_econ"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
